{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Datasets by Merging for Preprocessing"
      ],
      "metadata": {
        "id": "7tm5tWoedGH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv\")\n",
        "df.head(10)\n",
        "# Load CSV datasets into numpy arrays\n",
        "# data1 = np.genfromtxt('/content/dataset/Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv', delimiter=',', skip_header=1, usecols=range(17), dtype=str)\n",
        "# data2 = np.genfromtxt('/content/dataset/Crops production indicators - FAOSTAT_data_en_2-22-2024.csv', delimiter=',', skip_header=1, usecols=range(15), dtype=str)\n",
        "# data3 = np.genfromtxt('/content/dataset/Emissions - FAOSTAT_data_en_2-27-2024.csv', delimiter=',', skip_header=1, usecols=range(17), dtype=str)\n",
        "# data4 = np.genfromtxt('/content/dataset/Employment - FAOSTAT_data_en_2-27-2024.csv', delimiter=',', skip_header=1, usecols=range(20), dtype=str)\n",
        "# data5 = np.genfromtxt('/content/dataset/Exchange rate - FAOSTAT_data_en_2-22-2024.csv', delimiter=',', skip_header=1, usecols=range(16), dtype=str)\n",
        "# data6 = np.genfromtxt('/content/dataset/Fertilizers use - FAOSTAT_data_en_2-27-2024.csv', delimiter=',', skip_header=1, usecols=range(14), dtype=str)\n",
        "# data7 = np.genfromtxt('/content/dataset/Food balances indicators - FAOSTAT_data_en_2-22-2024.csv', delimiter=',', skip_header=1, usecols=range(14), dtype=str)\n",
        "# data8 = np.genfromtxt('/content/dataset/Food security indicators  - FAOSTAT_data_en_2-22-2024.csv', delimiter=',', skip_header=1, usecols=range(15), dtype=str)\n",
        "# data9 = np.genfromtxt('/content/dataset/Food trade indicators - FAOSTAT_data_en_2-22-2024.csv', delimiter=',', skip_header=1, usecols=range(15), dtype=str)\n",
        "# data10 = np.genfromtxt('/content/dataset/Foreign direct investment - FAOSTAT_data_en_2-27-2024.csv', delimiter=',', skip_header=1, usecols=range(15), dtype=str)\n",
        "# data11 = np.genfromtxt('/content/dataset/Land temperature change - FAOSTAT_data_en_2-27-2024.csv', delimiter=',', skip_header=1, usecols=range(14), dtype=str)\n",
        "# data12 = np.genfromtxt('/content/dataset/Land use - FAOSTAT_data_en_2-22-2024.csv', delimiter=',', skip_header=1, usecols=range(15), dtype=str)\n",
        "# data13 = np.genfromtxt('/content/dataset/Pesticides use - FAOSTAT_data_en_2-27-2024.csv', delimiter=',', skip_header=1, usecols=range(15), dtype=str)\n",
        "\n",
        "# Identify common column index (assuming it's the first column)\n",
        "# common_column_index = 3\n",
        "# print('Common_column:', common_column_index)\n",
        "# Find common values in the common column\n",
        "# common_values = np.intersect1d(data1[:, common_column_index])\n",
        "# for data in [data1, data2]:\n",
        "#      common_values = np.intersect1d(common_values, data[:, common_column_index])\n",
        "\n",
        "# print('Common Values', common_values)\n",
        "# Filter data based on common values\n",
        "# data1_filtered = data1[data1[:, common_column_index] == 'Nepal']\n",
        "# data2_filtered = data2[data2[:, common_column_index] == 'Nepal']\n",
        "# data3_filtered = data3[data3[:, common_column_index] == 'Nepal']\n",
        "# data4_filtered = data4[data4[:, common_column_index] == 'Nepal']\n",
        "# data5_filtered = data5[data5[:, common_column_index] == 'Nepal']\n",
        "# data6_filtered = data6[data6[:, common_column_index] == 'Nepal']\n",
        "# data7_filtered = data7[data7[:, common_column_index] == 'Nepal']\n",
        "# data8_filtered = data8[data8[:, common_column_index] == 'Nepal']\n",
        "# data9_filtered = data9[data9[:, common_column_index] == 'Nepal']\n",
        "# data10_filtered = data10[data10[:, common_column_index] == 'Nepal']\n",
        "# data11_filtered = data11[data11[:, common_column_index] == 'Nepal']\n",
        "# data12_filtered = data12[data12[:, common_column_index] == 'Nepal']\n",
        "# data13_filtered = data13[data13[:, common_column_index] == 'Nepal']\n",
        "\n",
        "# print('Data 1:', data1_filtered)\n",
        "# Extract only required columns (e.g., 2nd and 3rd columns)\n",
        "# required_columns_data1 = data1_filtered[:, [9, 11, 13]]\n",
        "# required_columns_data2 = data2_filtered[:, [9, 10, 11]]\n",
        "# required_columns_data3 = data3_filtered[:, [9, 12, 13]]\n",
        "# required_columns_data4 = data4_filtered[:, [9, 14, 15]]\n",
        "# required_columns_data5 = data5_filtered[:, [9, 12, 13]]\n",
        "# required_columns_data6 = data6_filtered[:, [9, 10, 11]]\n",
        "# required_columns_data7 = data7_filtered[:, [9, 10, 11]]\n",
        "# required_columns_data8 = data8_filtered[:, [9, 10, 11]]\n",
        "# required_columns_data9 = data9_filtered[:, [9, 10, 11]]\n",
        "# required_columns_data10 = data10_filtered[:, [9, 10, 11]]\n",
        "# required_columns_data11 = data11_filtered[:, [9, 10, 11]]\n",
        "# required_columns_data12 = data12_filtered[:, [9, 10, 11]]\n",
        "# required_columns_data13 = data13_filtered[:, [9, 10, 11]]\n",
        "\n",
        "# required_columns_data1_transposed = np.transpose(required_columns_data1)\n",
        "# required_columns_data2_transposed = np.transpose(required_columns_data2)\n",
        "# required_columns_data3_transposed = np.transpose(required_columns_data3)\n",
        "# required_columns_data4_transposed = np.transpose(required_columns_data4)\n",
        "# required_columns_data5_transposed = np.transpose(required_columns_data5)\n",
        "# required_columns_data6_transposed = np.transpose(required_columns_data6)\n",
        "# required_columns_data7_transposed = np.transpose(required_columns_data7)\n",
        "# required_columns_data8_transposed = np.transpose(required_columns_data8)\n",
        "# required_columns_data9_transposed = np.transpose(required_columns_data9)\n",
        "# required_columns_data10_transposed = np.transpose(required_columns_data10)\n",
        "# required_columns_data11_transposed = np.transpose(required_columns_data11)\n",
        "# required_columns_data12_transposed = np.transpose(required_columns_data12)\n",
        "# required_columns_data13_transposed = np.transpose(required_columns_data13)\n",
        "\n",
        "# Optionally merge datasets if needed\n",
        "# merged_data_transposed = np.concatenate((required_columns_data1_transposed, required_columns_data2_transposed), axis=1)\n",
        "\n",
        "# merged_data = np.column_stack(merged_data_transposed)\n",
        "\n",
        "# Save merged data as CSV file\n",
        "# try:\n",
        "#     # Save merged data as CSV file\n",
        "#     np.savetxt('/content/merged_data.csv', merged_data, delimiter=',', fmt='%s', comments='')\n",
        "#     print(\"File saved successfully.\")\n",
        "# except Exception as e:\n",
        "#     print(\"Error occurred during saving:\", e)\n"
      ],
      "metadata": {
        "id": "vtnOrlC-db7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(\"/content/Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv\", low_memory=True)\n",
        "df2 = pd.read_csv(\"/content/Crops production indicators - FAOSTAT_data_en_2-22-2024.csv\", low_memory=True)\n",
        "df3 = pd.read_csv(\"/content/Emissions - FAOSTAT_data_en_2-27-2024.csv\", low_memory=True)\n",
        "df4 = pd.read_csv(\"/content/Employment - FAOSTAT_data_en_2-27-2024.csv\", low_memory=True)\n",
        "df5 = pd.read_csv(\"/content/Exchange rate - FAOSTAT_data_en_2-22-2024.csv\", low_memory=True)\n",
        "df6 = pd.read_csv(\"/content/Fertilizers use - FAOSTAT_data_en_2-27-2024.csv\", low_memory=True)\n",
        "df7 = pd.read_csv(\"/content/Food balances indicators - FAOSTAT_data_en_2-22-2024.csv\", low_memory=True)\n",
        "df8 = pd.read_csv(\"/content/Food security indicators  - FAOSTAT_data_en_2-22-2024.csv\", low_memory=True)\n",
        "df9 = pd.read_csv(\"/content/Food trade indicators - FAOSTAT_data_en_2-22-2024.csv\", low_memory=True)\n",
        "df10 = pd.read_csv(\"/content/Foreign direct investment - FAOSTAT_data_en_2-27-2024.csv\", low_memory=True)\n",
        "df11 = pd.read_csv(\"/content/Land temperature change - FAOSTAT_data_en_2-27-2024.csv\", low_memory=True)\n",
        "df12 = pd.read_csv(\"/content/Land use - FAOSTAT_data_en_2-22-2024.csv\", low_memory=True)\n",
        "df13 = pd.read_csv(\"/content/Pesticides use - FAOSTAT_data_en_2-27-2024.csv\", low_memory=True)\n",
        "\n",
        "# List of columns to remove\n",
        "df1_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Months', 'Element Code', 'Element', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "df2_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element Code', 'Element', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "df3_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element', 'Source Code', 'Source', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "df4_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Element', 'Source Code', 'Source', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "df5_col_remove = ['Domain Code', 'Domain', 'ISO Currency Code (FAO)', 'Currency', 'Element Code', 'Year Code', 'Months', 'Element', 'Unit', 'Flag', 'Flag Description']\n",
        "df6_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element', 'Unit', 'Flag', 'Flag Description']\n",
        "df7_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element', 'Unit', 'Flag', 'Flag Description']\n",
        "df8_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "df9_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "df10_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "df11_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Months', 'Element', 'Unit', 'Flag', 'Flag Description']\n",
        "df12_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "df13_col_remove = ['Domain Code', 'Domain', 'Year Code', 'Item', 'Element', 'Unit', 'Flag', 'Flag Description', 'Note']\n",
        "\n",
        "\n",
        "# Remove the specified columns\n",
        "df1_new = df1.drop(columns=df1_col_remove)\n",
        "df2_new = df2.drop(columns=df2_col_remove)\n",
        "df3_new = df3.drop(columns=df3_col_remove)\n",
        "df4_new = df4.drop(columns=df4_col_remove)\n",
        "df5_new = df5.drop(columns=df5_col_remove)\n",
        "df6_new = df6.drop(columns=df6_col_remove)\n",
        "df7_new = df7.drop(columns=df7_col_remove)\n",
        "df8_new = df8.drop(columns=df8_col_remove)\n",
        "df9_new = df9.drop(columns=df9_col_remove)\n",
        "df10_new = df10.drop(columns=df10_col_remove)\n",
        "df11_new = df11.drop(columns=df11_col_remove)\n",
        "df12_new = df12.drop(columns=df12_col_remove)\n",
        "df13_new = df13.drop(columns=df13_col_remove)\n",
        "\n",
        "merged_df = pd.merge(df1, df2, on='Year', how='inner')\n",
        "\n",
        "merged_df.head(12)\n",
        "# data_list = [df1_new, df2_new, df3_new, df4_new, df5_new, df6_new, df7_new, df8_new, df9_new, df10_new, df11_new, df12_new, df13_new]\n",
        "\n",
        "# for i, data in enumerate(data_list, start=1):\n",
        "#     print(f\"DataFrame {i}:\\n\")\n",
        "#     print(data.head(12))  # Show the first 12 rows of each DataFrame\n",
        "#     print(\"\\n\")\n",
        "# df1_new.head(12)\n",
        "# df2_new.head(12)\n",
        "# df3_new.head(12)\n",
        "# df4_new.head(12)\n",
        "# df5_new.head(12)\n",
        "# df6_new.head(12)\n",
        "# df7_new.head(12)\n",
        "# df8_new.head(12)\n",
        "# df9_new.head(12)\n",
        "# df10_new.head(12)\n",
        "# df11_new.head(12)\n",
        "# df12_new.head(12)\n",
        "# df13_new.head(12)"
      ],
      "metadata": {
        "id": "FCDpaefr-CtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bbd717b-0cc4-47d4-b39f-a5cd0348bbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-67a211e5e64d>:14: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df12 = pd.read_csv(\"/content/Land use - FAOSTAT_data_en_2-22-2024.csv\", low_memory=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogGWYKTqhO42"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}